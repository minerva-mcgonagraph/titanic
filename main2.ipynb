{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minerva-mcgonagraph/titanic/blob/master/main2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiQsnnriyuqd",
        "colab_type": "text"
      },
      "source": [
        "If you went through my Chicken and Doggo notebook, you'll recall that the data (the images) were nice and neat. There weren't that many of them, there were about as many images of fried chicken as there were labradoodles, and they were all approximately the same size. If you didn't go through my Chicken and doggo notebook, then you probably think I'm mad. Just go through my chickken and doggo notebook. Join the madness. It's also cute.\n",
        "\n",
        "But unfortunately, data in the real world isn't so nice and cute. Problems often involve millions of rows of data. So instead of a proverbial sandbox, it's a more literal one: how do you turn all those grains of sand into a sparkling castle? That's what we're going to explore here.\n",
        "\n",
        "This notebook will use the python library pandas to do some feature engineering. Pandas is great if the data fits in memory. Since there's only a few hundred rows of data here, that's what we'll use.\n",
        "\n",
        "This data set is from the ongoing Kaggle competition.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZI8YxkiUPQ-H",
        "colab_type": "text"
      },
      "source": [
        "The next few code cells get the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmfNeUgitUkw",
        "colab_type": "code",
        "outputId": "b37f23fb-9156-4e90-e1bc-3bbc4d0c037c",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e6fbaf60-b46a-4d62-bd2c-00ab9fdfe20b\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-e6fbaf60-b46a-4d62-bd2c-00ab9fdfe20b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"minervamcgonagraph\",\"key\":\"74c142476e8374702f99fb22364fbc71\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4Inq1l4tUnK",
        "colab_type": "code",
        "outputId": "5f163fca-00ae-4599-bf87-a3741b0a05c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!ls ~/.kaggle"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_zwccYztUpo",
        "colab_type": "code",
        "outputId": "78bc7b0a-3a84-4428-a6ab-56af3fb9c9e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!ls -l ~/.kaggle\n",
        "!cat ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 4\n",
            "-rw------- 1 root root 74 Oct  7 20:02 kaggle.json\n",
            "{\"username\":\"minervamcgonagraph\",\"key\":\"74c142476e8374702f99fb22364fbc71\"}"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEyvx2z-tUr7",
        "colab_type": "code",
        "outputId": "71f2739c-d4f9-41d2-c1dc-eb80f8a7dda7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "!pip install -q kaggle\n",
        "!pip install -q kaggle-cli"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 81kB 1.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 5.3MB 4.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 51.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 21.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 53.9MB/s \n",
            "\u001b[?25h  Building wheel for kaggle-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVR1CK5utc65",
        "colab_type": "code",
        "outputId": "f3ed427b-30cd-4f0f-8c5a-dc0ca9da19e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "!kaggle datasets list"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "ref                                                       title                                               size  lastUpdated          downloadCount  \n",
            "--------------------------------------------------------  -------------------------------------------------  -----  -------------------  -------------  \n",
            "bradklassen/pga-tour-20102018-data                        PGA Tour Golf Data                                  98MB  2019-10-02 14:55:56           6764  \n",
            "martj42/international-football-results-from-1872-to-2017  International football results from 1872 to 2019   525KB  2019-10-02 16:51:16          21868  \n",
            "dgomonov/new-york-city-airbnb-open-data                   New York City Airbnb Open Data                       2MB  2019-08-12 16:24:45          23408  \n",
            "lakshyaag/india-trade-data                                India - Trade Data                                   1MB  2019-08-16 16:13:58          11102  \n",
            "therohk/ireland-historical-news                           The Irish Times - Waxy-Wany News                    47MB  2019-08-24 15:36:54           2361  \n",
            "dareenalharthi/jamalon-arabic-books-dataset               Jamalon Arabic Books Dataset                         1MB  2019-08-15 18:58:06            661  \n",
            "rajeevw/ufcdata                                           UFC-Fight historical data from 1993 to 2019          2MB  2019-07-05 09:58:02            850  \n",
            "ma7555/schengen-visa-stats                                Schengen Visa Stats 2017/2018                        1MB  2019-07-25 10:55:37           1834  \n",
            "shuyangli94/food-com-recipes-and-user-interactions        Food.com Recipes and Interactions                  261MB  2019-08-29 22:23:38            342  \n",
            "ruslankl/european-union-lgbt-survey-2012                  EU LGBT Survey                                     577KB  2019-07-19 11:15:25            276  \n",
            "tristan581/17k-apple-app-store-strategy-games             17K Mobile Strategy Games                            8MB  2019-08-26 08:22:16            503  \n",
            "akhilv11/border-crossing-entry-data                       Border Crossing Entry Data                           3MB  2019-08-21 14:51:34            382  \n",
            "codersree/mount-rainier-weather-and-climbing-data         Mount Rainier Weather and Climbing Data             25KB  2019-08-27 23:33:36           2132  \n",
            "kapilverma/hindi-bible                                    Hindi Bible                                          4MB  2019-09-07 18:04:35             39  \n",
            "samhiatt/xenocanto-avian-vocalizations-canv-usa           Avian Vocalizations from CA & NV, USA                1GB  2019-08-10 00:16:10            412  \n",
            "lishuyangkaggle/cocktails-hotaling-co                     Cocktails (Hotaling & Co.)                          75KB  2019-07-08 23:49:34           1713  \n",
            "gustavomodelli/forest-fires-in-brazil                     Forest Fires in Brazil                              31KB  2019-08-24 16:09:16            946  \n",
            "chirin/africa-economic-banking-and-systemic-crisis-data   Africa Economic, Banking and Systemic Crisis Data   14KB  2019-07-21 02:00:17            363  \n",
            "hmavrodiev/sofia-air-quality-dataset                      Sofia air quality dataset                            3GB  2019-09-14 05:48:09            116  \n",
            "valentynsichkar/traffic-signs-preprocessed                Traffic Signs Preprocessed                            0B  2019-08-31 18:22:11            107  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3Ac6wUytc9W",
        "colab_type": "code",
        "outputId": "0ea32709-4d87-471f-ba02-13d1bd0c6744",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "!kaggle competitions download -c titanic"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading train.csv to /content\n",
            "  0% 0.00/59.8k [00:00<?, ?B/s]\n",
            "100% 59.8k/59.8k [00:00<00:00, 24.4MB/s]\n",
            "Downloading test.csv to /content\n",
            "  0% 0.00/28.0k [00:00<?, ?B/s]\n",
            "100% 28.0k/28.0k [00:00<00:00, 28.2MB/s]\n",
            "Downloading gender_submission.csv to /content\n",
            "  0% 0.00/3.18k [00:00<?, ?B/s]\n",
            "100% 3.18k/3.18k [00:00<00:00, 1.33MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnZ4KvxqtdAA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuIx4Ns-jT2d",
        "colab_type": "text"
      },
      "source": [
        "Now we'll do some initial set up. We'll set all numbers to display to two decimal places and set the limit of table displays to 15 rows."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xpeab6zZjzii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#display preferences\n",
        "pd.options.display.float_format = '{:.2f}'.format\n",
        "pd.options.display.max_rows = 15\n",
        "\n",
        "#put the data into a readable format\n",
        "titanic_data = pd.read_csv('./train.csv')\n",
        "\n",
        "#randomize the data\n",
        "#note: the data has already been split so no need to worry about leaks\n",
        "titanic_data = titanic_data.reindex(np.random.permutation(titanic_data.index))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IG6nKqgslzZi",
        "colab_type": "text"
      },
      "source": [
        "now we'll do a first look at the data to see what we're working with. The training and test data combined account for a total of 1,309 passengers. Note that Titanic had a total of 1,317 passengers and a grand total of about 2,224 people on board (passengers and crew). For this project that's not important but that could affect the accuracy of the model in a real-world situation, since this model does not account for any crew members. Know your data!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYkM5PjRm6aq",
        "colab_type": "code",
        "outputId": "27520db9-38e1-4331-dff1-cb6b636a3e41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "#print the number of training examples\n",
        "print(\"There are\", len(titanic_data), \"examples in the training set.\")\n",
        "\n",
        "#look at a few rows to get an idea of what the data is like\n",
        "print(titanic_data[4:9])\n",
        "\n",
        "#show the header row which will become the feature names. Also show the type - numeric or categorical, since we will need to deal with these separately.\n",
        "titanic_data.dtypes\n",
        "\n",
        "#next: create two new dataframes, one with the numeric data and one with the categorical data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 891 examples in the training set.\n",
            "     PassengerId  Survived  Pclass  ...   Fare Cabin  Embarked\n",
            "319          320         1       1  ... 134.50   E34         C\n",
            "192          193         1       3  ...   7.85   NaN         S\n",
            "825          826         0       3  ...   6.95   NaN         Q\n",
            "800          801         0       2  ...  13.00   NaN         S\n",
            "651          652         1       2  ...  23.00   NaN         S\n",
            "\n",
            "[5 rows x 12 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PassengerId      int64\n",
              "Survived         int64\n",
              "Pclass           int64\n",
              "Name            object\n",
              "Sex             object\n",
              "Age            float64\n",
              "SibSp            int64\n",
              "Parch            int64\n",
              "Ticket          object\n",
              "Fare           float64\n",
              "Cabin           object\n",
              "Embarked        object\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPyNsTDS1Vjr",
        "colab_type": "text"
      },
      "source": [
        "From https://www.kaggle.com/c/titanic/data :\n",
        "\n",
        "Survival: 0 = No, 1 = Yes\n",
        "\n",
        "Pclass: ticket class, 1, 2, or 3\n",
        "\n",
        "Sex: sex\n",
        "\n",
        "Age: age in years; age is fractional if less than 1. If the age is estimated, it is in the form of xx.5\n",
        "\n",
        "SibSp: number of siblings, spouses also aboard; siblings include brother, sister, and stepbrother and stepsister; spouse includes husband or wife - fiances and mistresses were ignored\n",
        "\n",
        "Parch: number of parents, children also aboard; parent includes mother or father; child includes son, daughter, stepdaughter, stepson. Does not include nannies - some children travelled only with a nanny so this value is 0 for them.\n",
        "\n",
        "ticket: ticket number\n",
        "\n",
        "fare: passenger fare\n",
        "\n",
        "cabin: cabin number\n",
        "\n",
        "embarked: port of embarkation; C = Cherbourg, Q = Queenstown, S = Southampton"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nPp3P9e4atk",
        "colab_type": "text"
      },
      "source": [
        "Some questions:\n",
        "\n",
        "1. How many survived?\n",
        "\n",
        "2. How many first, second, and third class tickets were there?\n",
        "\n",
        "3. How many men vs women?\n",
        "\n",
        "4. What was the age distribution?\n",
        "\n",
        "5. Is sibsp,parch mean each family got 1 ticket or each ticket listed include familial relationships - ie, is the sum of sibsp and parch higher than the total number of passengers? How many travelled as a family and how many alone? Was someone more likely to survive if they travelled with family?\n",
        "\n",
        "6. What's the range of ticket numbers? Are they sequential or random (ie are there gaps)?\n",
        "\n",
        "7. What's the range in ticket prices? Were all tickets of each class type the same cost? Does this correlate more strongly with survival than class? Since fare and class are presumably strongly correlated, should we ignore one of them as a feature? (Which tf can do automatically)\n",
        "\n",
        "8. Can you tell what level each passenger was on based on the cabin number? Does that correlate with survival?\n",
        "\n",
        "9. How many embarked from each location?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgBznEB50ftG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ifc9og520f1k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2CZqyDu0f4L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45crua6H0f6z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVK0N-k-0f9P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}