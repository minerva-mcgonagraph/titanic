{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minerva-mcgonagraph/titanic/blob/master/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiQsnnriyuqd",
        "colab_type": "text"
      },
      "source": [
        "If you went through my Chicken and Doggo notebook, you'll recall that the data (the images) were nice and neat. There weren't that many of them, there were about as many images of fried chicken as there were labradoodles, and they were all approximately the same size. If you didn't go through my Chicken and doggo notebook, then you probably think I'm mad. Just go through my chickken and doggo notebook. Join the madness. It's also cute.\n",
        "\n",
        "But unfortunately, data in the real world isn't so nice and cute. Problems often involve millions of rows of data. So instead of a proverbial sandbox, it's a more literal one: how do you turn all those grains of sand into a sparkling castle? That's what we're going to explore here.\n",
        "\n",
        "This notebook will use the python library pandas to do some feature engineering. Pandas is great if the data fits in memory. Since there's only a few hundred rows of data here, that's what we'll use.\n",
        "\n",
        "This data set is from the ongoing Kaggle competition.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZI8YxkiUPQ-H",
        "colab_type": "text"
      },
      "source": [
        "First we need the data. Pro tip: this is the easiest way to access a data set from kaggle. You will need to go to your account and generate a new API key. Then open that donwloaded file in a text editor and copy/paste."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdZMrS8HytvN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "47863d95-358d-4efd-ae85-63600af8cce9"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import os\n",
        "os.environ['minervamcgonagraph'] = \"d5d9cffd4502b7f6be3e6ef7963c0aca\" #['username'] = \"key\"\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "!kaggle competitions download -c titanic"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train.csv: Skipping, found more recently modified local copy (use --force to force download)\n",
            "test.csv: Skipping, found more recently modified local copy (use --force to force download)\n",
            "gender_submission.csv: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuIx4Ns-jT2d",
        "colab_type": "text"
      },
      "source": [
        "Now we'll do some initial set up. We'll set all numbers to display to two decimal places and set the limit of table displays to 15 rows."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xpeab6zZjzii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#display preferences\n",
        "pd.options.display.float_format = '{:.2f}'.format\n",
        "pd.options.display.max_rows = 15\n",
        "\n",
        "#put the data into a readable format\n",
        "titanic_data = pd.read_csv('./train.csv')\n",
        "\n",
        "#randomize the data\n",
        "#note: the data has already been split so no need to worry about leaks\n",
        "titanic_data = titanic_data.reindex(np.random.permutation(titanic_data.index))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IG6nKqgslzZi",
        "colab_type": "text"
      },
      "source": [
        "now we'll do a first look at the data to see what we're working with. The training and test data combined account for a total of 1,309 passengers. Note that Titanic had a total of 1,317 passengers and a grand total of about 2,224 people on board (passengers and crew). For this project that's not important but that could affect the accuracy of the model in a real-world situation, since this model does not account for any crew members. Know your data!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYkM5PjRm6aq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "0e6e8e5b-0912-491a-f0e5-bf3db16d2aad"
      },
      "source": [
        "#print the number of training examples\n",
        "print(\"There are\", len(titanic_data), \"examples in the training set.\")\n",
        "\n",
        "#look at a few rows to get an idea of what the data is like\n",
        "print(titanic_data[4:9])\n",
        "\n",
        "#show the header row which will become the feature names. Also show the type - numeric or categorical, since we will need to deal with these separately.\n",
        "titanic_data.dtypes\n",
        "\n",
        "#next: create two new dataframes, one with the numeric data and one with the categorical data"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 891 examples in the training set.\n",
            "     PassengerId  Survived  Pclass  ...   Fare    Cabin  Embarked\n",
            "498          499         0       1  ... 151.55  C22 C26         S\n",
            "307          308         1       1  ... 108.90      C65         C\n",
            "514          515         0       3  ...   7.50      NaN         S\n",
            "656          657         0       3  ...   7.90      NaN         S\n",
            "18            19         0       3  ...  18.00      NaN         S\n",
            "\n",
            "[5 rows x 12 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PassengerId      int64\n",
              "Survived         int64\n",
              "Pclass           int64\n",
              "Name            object\n",
              "Sex             object\n",
              "Age            float64\n",
              "SibSp            int64\n",
              "Parch            int64\n",
              "Ticket          object\n",
              "Fare           float64\n",
              "Cabin           object\n",
              "Embarked        object\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    }
  ]
}